{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3171385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenm/.local/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model starting weights: ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1\n",
      "num_ftrs : 1280\n"
     ]
    }
   ],
   "source": [
    "#https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_h_14.html\n",
    "\n",
    "#ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1:\n",
    "\n",
    "#These weights are learnt via transfer learning by end-to-end fine-tuning the original SWAG weights on ImageNet-1K data. Also available as ViT_H_14_Weights.DEFAULT.\n",
    "\n",
    "#Perform the following preprocessing operations: \n",
    "#Accepts PIL.Image, \n",
    "#batched (B, C, H, W) and single (C, H, W) image torch.Tensor objects. \n",
    "#The images are resized to resize_size=[518] using interpolation=InterpolationMode.BICUBIC, \n",
    "#followed by a central crop of crop_size=[518].\n",
    "#Finally the values are first rescaled to [0.0, 1.0] and then normalized using mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225].\n",
    "#      transforms=partial(\n",
    "#             ImageClassification,\n",
    "#             crop_size=518,\n",
    "#             resize_size=518,\n",
    "#             interpolation=InterpolationMode.BICUBIC,\n",
    "#         )\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(f\"Using device: {device}\")\n",
    "\n",
    "# Download pretrained ViT weights and model\n",
    "vit_checkpoint = torchvision.models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "print(f\"model starting weights: {vit_checkpoint}\")\n",
    "\n",
    "model = torchvision.models.vit_h_14(weights=vit_checkpoint, progress=False)\n",
    "# Freeze the model parameters to perform fine tuning only on the last layer (classifier)\n",
    "for par in model.parameters():\n",
    "    par.requires_grad = False\n",
    "\n",
    "model = torchvision.models.vit_h_14(weights=vit_checkpoint, progress=False)\n",
    "\n",
    "num_ftrs = model.heads[-1].in_features\n",
    "print(f\"num_ftrs : {num_ftrs}\")\n",
    "\n",
    "num_output = 1\n",
    "model.heads[-1] = torch.nn.Linear(num_ftrs, num_output)\n",
    "\n",
    "model = nn.DataParallel(model) \n",
    "\n",
    "optimizer = optim.Adam(model.module.heads.parameters(), lr=1e-4)\n",
    "\n",
    "# For one-hot encoding use the BCE with logits loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a1004f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(trn_dl,model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    corrects = 0\n",
    "    # Iterate over data.\n",
    "    for i, (x, t) in enumerate(trn_dl):\n",
    "        print(i, x.shape, t.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        y_hat = torch.squeeze(y_hat)\n",
    "        #print(y_hat)\n",
    "        loss = criterion(y_hat, t.to(y_hat.device).float())\n",
    "\n",
    "        # backward + optimize only if in training phase\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_samples += x.size(0)\n",
    "    # Return the average training loss of ths epoch\n",
    "    return total_loss / total_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_labels, img_images, transforms_fn=None):\n",
    "        self.img_labels = img_labels\n",
    "        self.img_images = img_images\n",
    "        self.transforms_fn = transforms_fn\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img_images[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transforms_fn:\n",
    "            image = self.transforms_fn(image)\n",
    "        return image, label\n",
    "    \n",
    "###generate test dataset\n",
    "NUMBER_IMAGES = 20\n",
    "label_list = np.random.choice([1,2,3], size=NUMBER_IMAGES).tolist()\n",
    "images = torch.randint(0, 255, size=[NUMBER_IMAGES, 3, 518, 518], dtype=torch.uint8)\n",
    "image_dataset = ImageDataset(label_list, images, transforms_fn=vit_checkpoint.transforms())\n",
    "trn_dl = DataLoader(image_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97f6d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce01d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Start of epoch Memory usage: 5.56GB\n",
      "Before forward pass - Cuda memory cached: 2.671771648\n",
      "0 torch.Size([20, 3, 518, 518]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "model = model.cuda()\n",
    "num_epochs = 10\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "st = time.time()\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print(f'Epoch {e}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "    print(f\"Start of epoch Memory usage: {psutil.Process(os.getpid()).memory_info()[0] / 1e9:0.2f}GB\")\n",
    "    print(f'Before forward pass - Cuda memory cached: {torch.cuda.memory_cached()/1e9}')\n",
    "   \n",
    "    trn_loss = train_step(trn_dl, model, criterion, optimizer)\n",
    "    print(trn_loss)\n",
    "    trn_loss_list.append(trn_loss)    \n",
    "    print(f'Loss: {trn_loss:.4f}'\n",
    "          f\"end epoch Memory usage: {psutil.Process(os.getpid()).memory_info()[0] / 1e9:0.2f}GB\")\n",
    "print(f\"After Training Memory usage: {psutil.Process(os.getpid()).memory_info()[0] / 1e9:0.2f}GB\")\n",
    "\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
