{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ec53f8b-1517-4a6f-bf99-52f112a11196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "import tqdm\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import zarr\n",
    "import dask\n",
    "import dask.array as da\n",
    "import zarrdataset\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c942a-c7ab-44cc-9b81-260993480ff5",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31d88311-8243-41f5-81e9-62f179d68c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 4\n",
    "patch_size = 518\n",
    "num_workers = 0\n",
    "\n",
    "num_classes = 1\n",
    "bias = True\n",
    "\n",
    "rng_seed = -1\n",
    "\n",
    "log_dir = \"/fastscratch/cervaf/logs/wsi_classifiers/\"\n",
    "log_identifier = \"ViT_H_14\"\n",
    "print_log = True\n",
    "\n",
    "trn_filenames_list = \"/projects/researchit/cervaf/s3_bucket_data/tcga_kirc_train.txt\"\n",
    "val_filenames_list = \"/projects/researchit/cervaf/s3_bucket_data/tcga_kirc_val.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba32fa-b811-476f-9eb5-cd60db51c0aa",
   "metadata": {},
   "source": [
    "### Set a random number generator seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3c68139-c188-49da-8158-f4cac5790d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rng_seed < 0:\n",
    "    rng_seed = np.random.randint(1, 100000)\n",
    "\n",
    "torch.manual_seed(rng_seed)\n",
    "np.random.seed(rng_seed + 1)\n",
    "random.seed(rng_seed+1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a96e39-c234-444e-ad24-871e4ca9fd1e",
   "metadata": {},
   "source": [
    "### Helper function to load the dataset filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8951dcee-887d-4b91-b14f-514c1c3ab4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filenames_list(filenames_list, input_format):\n",
    "    if (isinstance(filenames_list, str)\n",
    "      and not (filenames_list.lower().endswith(input_format.lower())\n",
    "             or filenames_list.lower().endswith(\".txt\"))):\n",
    "        return []\n",
    "\n",
    "    if (isinstance(filenames_list, str)\n",
    "      and filenames_list.lower().endswith(input_format.lower())):\n",
    "        return [filenames_list]\n",
    "\n",
    "    if (isinstance(filenames_list, str)\n",
    "      and filenames_list.lower().endswith(\".txt\")):\n",
    "        with open(filenames_list, \"r\") as fp:\n",
    "            filenames_list = [fn.strip(\"\\n \") for fn in  fp.readlines()]\n",
    "\n",
    "    if isinstance(filenames_list, list):\n",
    "        filenames_list = functools.reduce(lambda l1, l2: l1 + l2,\n",
    "                                          map(parse_filenames_list,\n",
    "                                              filenames_list,\n",
    "                                              itertools.repeat(input_format)),\n",
    "                                          [])\n",
    "    return filenames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a946499a-ac16-4630-97db-ca0cf41ea5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('train_log')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fh = logging.FileHandler(os.path.join(log_dir, \"train_vit_classifier%s.log\" % log_identifier), mode='w')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "if print_log:\n",
    "    console = logging.StreamHandler()\n",
    "    console.setFormatter(formatter)\n",
    "    logger.addHandler(console)\n",
    "    console.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ec2ee-fd68-48f8-a896-04ac56613abb",
   "metadata": {},
   "source": [
    "# Load the pretrained Vision Transoformer (ViT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e06807-5f3c-4927-b892-ce1937024edd",
   "metadata": {},
   "source": [
    "### Setup a ViT model using the pre-trained weights provided by torchvision at\n",
    "https://pytorch.org/vision/main/models/generated/torchvision.models.vit_h_14.html#vit-h-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a39c278d-a274-4e23-8163-b4f0d7aa6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:56:58,505 - INFO - Loading vision transformer from torchvision.models.vit_b_16\n",
      "2023-06-26 15:56:58,505 - INFO - Loading vision transformer from torchvision.models.vit_b_16\n",
      "2023-06-26 15:56:58,505 - INFO - Loading vision transformer from torchvision.models.vit_b_16\n",
      "2023-06-26 15:57:07,468 - INFO - Preprocessing transforms\n",
      "functools.partial(<class 'torchvision.transforms._presets.ImageClassification'>, crop_size=518, resize_size=518, interpolation=<InterpolationMode.BICUBIC: 'bicubic'>)\n",
      "2023-06-26 15:57:07,468 - INFO - Preprocessing transforms\n",
      "functools.partial(<class 'torchvision.transforms._presets.ImageClassification'>, crop_size=518, resize_size=518, interpolation=<InterpolationMode.BICUBIC: 'bicubic'>)\n",
      "2023-06-26 15:57:07,468 - INFO - Preprocessing transforms\n",
      "functools.partial(<class 'torchvision.transforms._presets.ImageClassification'>, crop_size=518, resize_size=518, interpolation=<InterpolationMode.BICUBIC: 'bicubic'>)\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('train_log')\n",
    "\n",
    "logger.info(\"Loading vision transformer from torchvision.models.vit_b_16\")\n",
    "\n",
    "vit_checkpoint = torchvision.models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "model = torchvision.models.vit_h_14(weights=vit_checkpoint, progress=False)\n",
    "\n",
    "# Freeze the model parameters to perform fine tuning only on the last layer (classifier)\n",
    "for par in model.parameters():\n",
    "    par.requires_grad = False\n",
    "\n",
    "model.heads = nn.Sequential(\n",
    "    nn.Linear(in_features=1280, out_features=num_classes, bias=bias)\n",
    ")\n",
    "\n",
    "logger.debug(\"Model\\n%s\" % str(model))\n",
    "extra_transforms = vit_checkpoint.transforms\n",
    "\n",
    "logger.info(\"Preprocessing transforms\\n%s\" % extra_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c95187-5c0c-41d0-be66-01f9057d4cdf",
   "metadata": {},
   "source": [
    "## Define the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9a04ead-4e91-4803-a8e6-9d844532fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an auxiliary class that extracts patches from the zarr files without having to save them separately\n",
    "patch_sampler = zarrdataset.GridPatchSampler(patch_size=patch_size)\n",
    "\n",
    "transforms_pipeline = [\n",
    "    zarrdataset.SelectAxes(\"TCZYX\", {\"T\":0, \"Z\":0}, \"YXC\"),\n",
    "    zarrdataset.ZarrToArray(dtype=np.uint8),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "]\n",
    "\n",
    "if extra_transforms is not None:\n",
    "    transforms_pipeline.append(extra_transforms())\n",
    "\n",
    "input_transforms = torchvision.transforms.Compose(transforms_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1551d-29e3-4645-89f4-6bf9fe87db3f",
   "metadata": {},
   "source": [
    "### Get the training and validation file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9710b155-ce66-4e8d-ad8e-105a321d4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_filenames = parse_filenames_list(trn_filenames_list, \".zarr\")\n",
    "val_filenames = parse_filenames_list(val_filenames_list, \".zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee6f8946-1400-4b25-9843-83b81c700015",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(f\"Training files\\n{trn_filenames}\")\n",
    "logger.debug(f\"Validation files\\n{val_filenames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94a540c2-5b09-444d-aeee-55091ff41fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = zarrdataset.LabeledZarrDataset(\n",
    "    trn_filenames[:2],\n",
    "    data_group=\"0/0\", data_axes=\"TCZYX\",\n",
    "    mask_data_group=\"masks/0/0\", mask_data_axes=\"YX\",\n",
    "    labels_data_group=\"masks/1/1\", labels_data_axes=\"C\",\n",
    "    transform=input_transforms,\n",
    "    shuffle=True,\n",
    "    patch_sampler=patch_sampler,\n",
    "    draw_same_chunk=True,\n",
    "    progress_bar=False,\n",
    "    use_dask=False)\n",
    "\n",
    "val_ds = zarrdataset.LabeledZarrDataset(\n",
    "    val_filenames[:2],\n",
    "    data_group=\"0/0\", data_axes=\"TCZYX\",\n",
    "    mask_data_group=\"masks/0/0\", mask_data_axes=\"YX\",\n",
    "    labels_data_group=\"masks/1/1\", labels_data_axes=\"C\",\n",
    "    transform=input_transforms,\n",
    "    shuffle=False,\n",
    "    patch_sampler=patch_sampler,\n",
    "    draw_same_chunk=True,\n",
    "    progress_bar=False,\n",
    "    use_dask=False)\n",
    "\n",
    "trn_dl = DataLoader(\n",
    "    trn_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=zarrdataset.zarrdataset_worker_init,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=num_workers > 0\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=zarrdataset.zarrdataset_worker_init,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=num_workers > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca7e3c-4d85-4991-a99b-d9d70c7c9ac7",
   "metadata": {},
   "source": [
    "## Define the optimizer and the criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ebeb09f7-5651-4083-a4ca-de3cce9d9646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:57:08,115 - INFO - Optimizer: Adam, lr=1e-4\n",
      "2023-06-26 15:57:08,115 - INFO - Optimizer: Adam, lr=1e-4\n",
      "2023-06-26 15:57:08,115 - INFO - Optimizer: Adam, lr=1e-4\n",
      "2023-06-26 15:57:08,366 - INFO - Criterion: BCE with logits\n",
      "2023-06-26 15:57:08,366 - INFO - Criterion: BCE with logits\n",
      "2023-06-26 15:57:08,366 - INFO - Criterion: BCE with logits\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# Optimize only the classifier head of the model, since everything else is frozen\n",
    "optimizer = optim.Adam(model.heads.parameters(), lr=1e-4)\n",
    "\n",
    "# For one-hot encoding use the BCE with logits loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "logger.info(\"Optimizer: Adam, lr=1e-4\")\n",
    "logger.info(\"Criterion: BCE with logits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abe3b0-9b97-473c-b647-eee7991228e4",
   "metadata": {},
   "source": [
    "## Define the training and validation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bb06a7b-55b0-40ca-9bca-350fe882b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(trn_dl, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (x, t) in enumerate(trn_dl):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(x.cuda())\n",
    "\n",
    "        loss = criterion(y_hat, t.to(y_hat.device).float())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            logger.debug(f\"Training step {i}, avg. training loss={total_loss / total_samples}\")\n",
    "\n",
    "    # Return the average training loss of ths epoch\n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cacaa9f-5370-4860-a012-c8d10c2b8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(val_dl, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, t) in enumerate(val_dl):\n",
    "            y_hat = model(x.cuda())\n",
    "            loss = criterion(y_hat, t.to(y_hat.device).float())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_samples += x.size(0)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                logger.debug(f\"Validation step {i}, avg. validation loss={total_loss / total_samples}\")\n",
    "\n",
    "    # Return the average validation loss of this epoch\n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147238ed-13e6-4535-a136-86e670e27a59",
   "metadata": {},
   "source": [
    "# The main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ea305e2-b56e-47b3-a7f7-e1b5bffdabc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 16:20:23,964 - INFO - Epoch 1, avg. training loss=0.002234800590497446, avg. validation loss=0.0002953684325151049\n",
      "2023-06-26 16:20:23,964 - INFO - Epoch 1, avg. training loss=0.002234800590497446, avg. validation loss=0.0002953684325151049\n",
      "2023-06-26 16:20:23,964 - INFO - Epoch 1, avg. training loss=0.002234800590497446, avg. validation loss=0.0002953684325151049\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "last_checkpoint_fn = os.path.join(log_dir, \"last_vit_classifier%s.pth\" % log_identifier)\n",
    "best_checkpoint_fn = os.path.join(log_dir, \"best_vit_classifier%s.pth\" % log_identifier)\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    trn_loss = train_step(trn_dl, model, criterion, optimizer)\n",
    "    val_loss = validation_step(val_dl, model, criterion)\n",
    "\n",
    "    trn_loss_list.append(trn_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "\n",
    "    last_checkpoint = dict(\n",
    "        model=model.state_dict(),\n",
    "        epoch=e,\n",
    "        trn_loss=trn_loss_list,\n",
    "        val_loss=val_loss_list,\n",
    "        best_val_loss=best_val_loss)\n",
    "    torch.save(last_checkpoint, last_checkpoint_fn)\n",
    "\n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_checkpoint = dict(\n",
    "            model=model.state_dict(),\n",
    "            epoch=e,\n",
    "            trn_loss=trn_loss_list,\n",
    "            val_loss=val_loss_list,\n",
    "            best_val_loss=best_val_loss)\n",
    "        torch.save(best_checkpoint, best_checkpoint_fn)\n",
    "\n",
    "    logger.info(f\"Epoch {e + 1}, avg. training loss={trn_loss}, avg. validation loss={val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
